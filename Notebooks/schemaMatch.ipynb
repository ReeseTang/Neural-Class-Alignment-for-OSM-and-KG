{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense\n",
    "import pickle\n",
    "import psycopg2\n",
    "import scipy\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "from keras import activations\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"Italy\"\n",
    "KG = \"Wikidata\" #options: Wikidata/Wikipedia\n",
    "data = pd.read_csv('Data/'+KG+'/'+country+'/'+country+'.csv', sep='\\t', encoding='utf-8',)\n",
    "latentSpace = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = data._get_numeric_data()\n",
    "num[num > 1] = 1\n",
    "labelName = []\n",
    "colNameOsm = []\n",
    "colNameWiki = []\n",
    "for col in data.columns:\n",
    "    if 'cls_' in col:\n",
    "        labelName.append(col)\n",
    "    if 'osmTagKey_' in col:\n",
    "        try:\n",
    "            if data[col].value_counts()[1]>50:\n",
    "                colNameOsm.append(col)\n",
    "        except KeyError:\n",
    "            KeyError\n",
    "    elif 'prop_' in col and 'prop_instance of' not in col:\n",
    "        colNameWiki.append(col)\n",
    "labels =  data[labelName]\n",
    "columnsOSM = data[colNameOsm]\n",
    "columnsWiki = data[colNameWiki]\n",
    "labelNameDict = {}\n",
    "for i in range(len(labelName)):\n",
    "    labelNameDict[i] = labelName[i]\n",
    "columnsWikiDict = {}\n",
    "for i in range(len(colNameWiki)):\n",
    "    columnsWikiDict[i] = colNameWiki[i]\n",
    "colNameOsmDict = {}\n",
    "for i in range(len(colNameOsm)):\n",
    "    colNameOsmDict[i] = colNameOsm[i]\n",
    "        #print(c)\n",
    "columns = colNameOsm+colNameWiki\n",
    "columnsDict = {}\n",
    "for i in range(len(columns)):\n",
    "    columnsDict[i] = columns[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_var = 1\n",
    "kf = KFold(n_splits = 3, random_state = 42, shuffle = True)\n",
    "train_index, val_index = list(kf.split(columnsOSM,labels))[0]\n",
    "osm_train = columnsOSM.iloc[train_index].values\n",
    "osm_test = columnsOSM.iloc[val_index].values\n",
    "wiki_train = columnsWiki.iloc[train_index].values\n",
    "wiki_test = columnsWiki.iloc[val_index].values\n",
    "y_train = labels.iloc[train_index].values\n",
    "y_test = labels.iloc[val_index].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training data for discriminator\n",
    "def generate_adverse_labels(osm, wiki):\n",
    "    osm_part = np.ones((osm.shape[0], 1))\n",
    "    wiki_part = np.zeros((wiki.shape[0], 1))\n",
    "    return np.concatenate((osm_part, wiki_part))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(x,y):\n",
    "    # Import a dataset with X and multi-label y\n",
    "\n",
    "    lp = LabelPowerset()\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "    # Applies the above stated multi-label (ML) to multi-class (MC) transformation.\n",
    "    yt = lp.transform(y)\n",
    "\n",
    "    X_resampled, y_resampled = ros.fit_sample(x, yt)\n",
    "    # Inverts the ML-MC transformation to recreate the ML set\n",
    "    y_resampled = lp.inverse_transform(y_resampled)\n",
    "    y_resampled = y_resampled.toarray()\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_input(osm_train, osm_test, wiki_train, wiki_test, y_train, y_test):\n",
    "    \n",
    "    #total length of the input = OSM tags + OSM keys + KG properties\n",
    "    maxlen =osm_train.shape[1]+wiki_train.shape[1]\n",
    "    osm_train_pad = pad_sequences(osm_train, padding='post', maxlen=maxlen)\n",
    "    osm_test_pad = pad_sequences(osm_test, padding='post', maxlen=maxlen)\n",
    "    wiki_train_pad = pad_sequences(wiki_train, padding='pre', maxlen=maxlen)\n",
    "    wiki_test_pad = pad_sequences(wiki_test, padding='pre', maxlen=maxlen)\n",
    "    \n",
    "    print(\"osm_train\", osm_train_pad.shape, \"wiki_train\", wiki_train_pad.shape)\n",
    "    x_train = np.concatenate((osm_train_pad, wiki_train_pad))\n",
    "    print(\"x_train\", x_train.shape)\n",
    "\n",
    "    print(\"osm_test\", osm_test_pad.shape, \"wiki_test\", wiki_test_pad.shape)\n",
    "    x_test = np.concatenate((osm_test_pad, wiki_test_pad))\n",
    "    print(\"x_test\", x_test.shape)\n",
    "\n",
    "    print(\"y_train\", y_train.shape)\n",
    "    y_train = np.concatenate((y_train, y_train))\n",
    "    print(\"y_train\", y_train.shape)\n",
    "\n",
    "    print(\"y_test\", y_test.shape)\n",
    "    y_test = np.concatenate((y_test, y_test))\n",
    "    print(\"y_test\", y_test.shape)\n",
    "\n",
    "    adverse_train = generate_adverse_labels(osm_train, wiki_train)\n",
    "    print(\"adverse_train\", adverse_train.shape)\n",
    "    adverse_test = generate_adverse_labels(osm_test, wiki_test)\n",
    "    print(\"adverse_test\", adverse_test.shape)\n",
    "\n",
    "    \n",
    "    return x_train, y_train, adverse_train, x_test, y_test, adverse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, adverse_train, x_test, y_test, adverse_test = transform_input(osm_train, osm_test, wiki_train, wiki_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss for adversarial component\n",
    "def maxLoss(y_true, y_pred):\n",
    "    return -1.0 * binary_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaModel:\n",
    "\n",
    "    def __init__(self, no_inputs, no_outputs):\n",
    "        optimizer = Adam(0.0001, 0.5)\n",
    "        self.model = self.define_discriminator(no_inputs, no_outputs)\n",
    "        \n",
    "        losses = {\n",
    "                \"class\": 'binary_crossentropy',\n",
    "                \"adverse\": maxLoss,\n",
    "                }\n",
    "        self.model.compile(loss=losses,\n",
    "                                   optimizer=optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "    def define_discriminator(self, no_inputs, no_outputs):\n",
    "        inputs = Input(shape=(no_inputs,), name = 'input')\n",
    "        \n",
    "        X_1 = Dense(100, activation='relu', name = 'layer1')(inputs)\n",
    "        latent_rep = Dense(latentSpace, activation='relu', name = 'latentRep')(X_1)\n",
    "\n",
    "        # KG classfication\n",
    "        fc_1 = Dense(latentSpace, activation='relu', name = 'layer3')(latent_rep)\n",
    "        fc_2 = Dense(latentSpace , activation='relu', name = 'layer4')(fc_1)\n",
    "        \n",
    "        classifier = Dense(no_outputs, activation='sigmoid', name = 'class')(fc_2)\n",
    "        \n",
    "        #adversarial compenent\n",
    "        adverse= Dense(1, activation='softmax', name = 'adverse')(latent_rep)\n",
    "        \n",
    "        \n",
    "        model = Model(inputs, [classifier, adverse])\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Setting the seed for numpy-generated random numbers\n",
    "np.random.seed(0)\n",
    "\n",
    "# Setting the seed for python random numbers\n",
    "rn.seed(1254)\n",
    "\n",
    "# Setting the graph-level random seed.\n",
    "tf.set_random_seed(89)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "session_conf = tf.ConfigProto(\n",
    "      intra_op_parallelism_threads=1,\n",
    "      inter_op_parallelism_threads=1)\n",
    "\n",
    "#Force Tensorflow to use a single thread\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SchemaModel(x_train.shape[1], y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = m.model.fit(x=x_train, y=[y_train, adverse_train], epochs=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassIndex(clsId, y_test):\n",
    "    t = np.argwhere(y_test>0)\n",
    "    clsIndex = []\n",
    "    for i in range(len(t)):\n",
    "        if t[i][1] == clsId:\n",
    "            clsIndex.append(t[i][0])\n",
    "    return clsIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassAcc(y_test, y_pred, cls, threshold):\n",
    "    indexes = getClassIndex(cls, y_test)\n",
    "    total_number = len(indexes)\n",
    "    fn = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if i in indexes:\n",
    "            if y_pred[i][cls]>threshold:\n",
    "                tp = tp+1\n",
    "            elif y_pred[i][cls]<threshold:\n",
    "                fn = fn+1\n",
    "        elif i not in indexes:\n",
    "            if y_pred[i][cls]>threshold:\n",
    "                fp = fp+1\n",
    "    try:\n",
    "        precision = tp/(tp+fp)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0\n",
    "    try:\n",
    "        recall = tp/(tp+fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0\n",
    "    return cls, total_number, precision, recall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = m.model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get per class accuracy\n",
    "for i in range(y_test.shape[1]):\n",
    "    print(getClassAcc(y_test, a[0],i , 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the array for testing with one row for 1 input\n",
    "testKeyTag = np.zeros((x_train.shape[1], x_train.shape[1]))\n",
    "for i in range(len(testKeyTag)):\n",
    "    testKeyTag[i][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the activations of the last layer\n",
    "get_layer_output = K.function([m.model.layers[0].input],\n",
    "                                  [m.model.layers[5].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output = get_layer_output(testKeyTag)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatches():\n",
    "    listPrecRecall = []\n",
    "    for i in range(len(testKeyTag)):\n",
    "        if '=' in columnsDict[np.argmax(testKeyTag[i])] and not any(map(str.isdigit, columnsDict[np.argmax(testKeyTag[i])]))  and '=yes' not in columnsDict[np.argmax(testKeyTag[i])] and '=no' not in columnsDict[np.argmax(testKeyTag[i])]:\n",
    "            for j in range(len(layer_output[i])):\n",
    "                listPrecRecall.append((columnsDict[np.argmax(testKeyTag[i])].replace('osmTagKey_',''),labelNameDict[j].replace('cls_',''), layer_output[i][j]))\n",
    "    return listPrecRecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = getMatches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
