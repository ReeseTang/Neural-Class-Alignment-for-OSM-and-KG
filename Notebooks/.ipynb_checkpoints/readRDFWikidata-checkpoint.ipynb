{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "import time\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "import psycopg2\n",
    "import pickle\n",
    "import random\n",
    "from urllib.error import HTTPError, URLError\n",
    "from qwikidata.sparql  import return_sparql_query_results\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open(\"italyRdf.txt\", \"r\") as a_file:\n",
    "    for line in a_file:\n",
    "        stripped_line = line.strip()\n",
    "        lines.append(re.split(r'\\t', stripped_line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lines)):\n",
    "    try:\n",
    "        if len(lines[i])<3:\n",
    "            lines.remove(lines[i])\n",
    "    except IndexError:\n",
    "        lines.remove(lines[i]) ###remove this later\n",
    "        break\n",
    "    if len(lines[i])>4:\n",
    "        del lines[i][3:]\n",
    "    if len(lines[i])==4:\n",
    "        del lines[i][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = []\n",
    "key = []\n",
    "value = []\n",
    "for i in range(len(lines)):\n",
    "    node.append(lines[i][0])\n",
    "    key.append(lines[i][1])\n",
    "    value.append(lines[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(node)):\n",
    "    node[i] = node[i].replace('<https://www.openstreetmap.org/node/','')\n",
    "    node[i] = node[i].replace('>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(node)):\n",
    "    key[i] = key[i].replace('<https://wiki.openstreetmap.org/wiki/Key:','')\n",
    "    key[i] = key[i].replace('>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(zip(node, key, value)),columns = ['node','key', 'value']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['value'] = data['value'].str.replace('\\\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tagKey'] = data[['key', 'value']].apply(lambda x: '='.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.key != '<http://www.w3.org/2003/01/geo/wgs84_pos#long') & (data.key != '<http://www.w3.org/2003/01/geo/wgs84_pos#Point')]\n",
    "data = data[(data.key != '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type') & (data.key != '<http://www.w3.org/2003/01/geo/wgs84_pos#lat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data for tags and keys of OSM.\n",
    "osmTag = pd.read_csv('osmTagKeyWiki.csv', sep=',', encoding='utf-8',)\n",
    "osmKey = pd.read_csv('osmKeyWiki.csv', sep=',', encoding='utf-8',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osmKey = osmKey.drop_duplicates(subset='Keys', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(osmKey.Keys.values)\n",
    "tags = list(osmTag.Tags.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tags for key-value pair\n",
    "osm_id = []\n",
    "osmwiki_id = []\n",
    "osmtagkey = []\n",
    "osmvalue = []\n",
    "wikidata = []\n",
    "for index, row in data.iterrows():\n",
    "    if row['key'] == 'wikidata':\n",
    "        wikidata.append(row['value'])\n",
    "        osmwiki_id.append(row['node'])\n",
    "    if row['tagKey'] in tags:\n",
    "        osm_id.append(row['node'])\n",
    "        osmtagkey.append(row['tagKey'])\n",
    "        osmvalue.append(row['value'])\n",
    "    else:\n",
    "        osm_id.append(row['node'])\n",
    "        osmtagkey.append(row['key'])\n",
    "        osmvalue.append(row['value'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osmdata = pd.DataFrame(list(zip(osm_id, osmtagkey, osmvalue)),columns = ['osm_id','osmTagKey', 'value']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osmWiki = pd.DataFrame(list(zip(osmwiki_id, wikidata)),columns = ['osm_id','wikidata']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osmdata = pd.merge(osmWiki, osmdata, on = 'osm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiEnt= list(set(list(data.loc[data['key'] == 'wikidata', 'value'])))\n",
    "for i in range(len(wikiEnt)):\n",
    "    wikiEnt[i] = wikiEnt[i].replace('\\\"','')\n",
    "#remove values which do not have wikidata format: Q----\n",
    "regex = re.compile('(Q)[0-9]+')\n",
    "wikiEnt = [x for x in wikiEnt if regex.match(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    # TODO adjust user agent; see https://w.wiki/CX6\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "wiki_Data = []\n",
    "i=0\n",
    "while  i < len(wikiEnt):\n",
    "    new_lst = wikiEnt[i:i+300]\n",
    "    mystring = ''.join('wd:{0} '.format(w) for w in new_lst)\n",
    "    query = \"\"\"SELECT ?kgentity  ?wdLabel ?ps_Label {\n",
    "  VALUES ?kgentity {wd:%s}\n",
    "  ?kgentity ?p ?statement .\n",
    "  ?statement ?ps ?ps_ .\n",
    "  \n",
    "  ?wd wikibase:claim ?p.\n",
    "  ?wd wikibase:statementProperty ?ps.\n",
    "  \n",
    "  OPTIONAL {\n",
    "  ?statement ?pq ?pq_ .\n",
    "  ?wdpq wikibase:qualifier ?pq .\n",
    "  }\n",
    "  \n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" }\n",
    "} ORDER BY ?wd ?statement ?ps_\"\"\"%mystring\n",
    "\n",
    "    results = get_results(endpoint_url, query)\n",
    "    wiki_Data.append(results)\n",
    "    #print('itt'+ str(i))\n",
    "    i=i+300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgentity = []\n",
    "wdLabel = []\n",
    "ps_Label = []\n",
    "for i in range(len(wiki_Data)):\n",
    "    for j in range(len(wiki_Data[i]['results']['bindings'])):\n",
    "        kgentity.append(wiki_Data[i]['results']['bindings'][j]['kgentity']['value'])\n",
    "        wdLabel.append(wiki_Data[i]['results']['bindings'][j]['wdLabel']['value'])\n",
    "        ps_Label.append(wiki_Data[i]['results']['bindings'][j]['ps_Label']['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(kgentity)):\n",
    "    kgentity[i] = kgentity[i].replace('http://www.wikidata.org/entity/','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidataTable = pd.DataFrame(list(zip(kgentity, wdLabel, ps_Label)),columns = ['wikidata','prop', 'value']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiForClass = []\n",
    "temp = []\n",
    "cls = []\n",
    "wikidata = []\n",
    "for i in range(len(wiki_Data)):\n",
    "    for j in range(len(wiki_Data[i]['results']['bindings'])):\n",
    "        temp.append(wiki_Data[i]['results']['bindings'][j]['wdLabel']['value'])\n",
    "        wikidata.append(wiki_Data[i]['results']['bindings'][j]['kgentity']['value'].replace('http://www.wikidata.org/entity/',''))\n",
    "        if (wiki_Data[i]['results']['bindings'][j]['wdLabel']['value'] == 'instance of'):\n",
    "            cls.append(wiki_Data[i]['results']['bindings'][j]['ps_Label']['value'])\n",
    "            wikiForClass.append(wiki_Data[i]['results']['bindings'][j]['kgentity']['value'].replace('http://www.wikidata.org/entity/',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidataTable = wikidataTable.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidatacls = wikidatacls.rename(columns={\"value\": \"cls\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wikidataToConsider = wikidatacls[wikidatacls['cls'].isin(wikidatacls['cls'].value_counts()[wikidatacls['cls'].value_counts()> 100].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidataTest = pd.merge(wikidataTable,wikidataToConsider, on='wikidata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = []\n",
    "className = []\n",
    "PropName = []\n",
    "for j in (list(wikidataTest['cls'].unique())):\n",
    "    if j == 'human':\n",
    "        continue\n",
    "    else:\n",
    "        for i in (list(wikidataTest[wikidataTest['cls']==j]['prop'].unique())):\n",
    "            tf = len(wikidataTest[(wikidataTest['cls']== j) & (wikidataTest['prop']== i)])\n",
    "            df = len(wikidataTest[wikidataTest['prop']== i]['cls'].value_counts())\n",
    "            N = 40\n",
    "            weight = tf * (np.log (N/df))\n",
    "            if weight == 0:\n",
    "                continue\n",
    "            else:\n",
    "                tfidf.append(weight)\n",
    "                className.append(j)\n",
    "                propName.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfweights = pd.DataFrame(list(zip(className, propName, tfidf)),\n",
    "                    columns = ['cls', 'prop', 'tfidfval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupsort = tfidfweights.sort_values(['cls'], ascending=True).groupby(['cls'], sort=False).apply(lambda x: x.sort_values(['tfidfval'], ascending=False)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupsort = groupsort.groupby('cls').head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentList = list(groupsort.prop.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidataTable = wikidataTable[wikidataTable['prop'].isin(currentList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osmdata = pd.merge(osmdata, wikidataToConsider, on = 'wikidata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\"osmTag\"]\n",
    "onehotTags = pd.get_dummies(osmdata, prefix_sep=\"_\", columns=cat_columns)\n",
    "onehotTags = onehotTags.groupby(['osm_id','wikidata'], as_index = False).sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\"prop\"]\n",
    "oneHotWikiProp = pd.get_dummies(wikidataTable, prefix_sep=\"_\", columns=cat_columns)\n",
    "oneHotWikiProp = oneHotWikiProp.groupby(oneHotWikiProp['wikidata'], as_index = False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\"cls\"]\n",
    "onehotClass = pd.get_dummies(wikidataToConsider, prefix_sep=\"_\", columns=cat_columns)\n",
    "onehotClass = onehotClass.groupby(onehotClass['wikidata'], as_index = False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempMerge = pd.merge(oneHotWikiProp, onehotClass, on = 'wikidata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.merge(onehotTags,tempMerge, on = 'wikidata' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data for the particular country and the KG\n",
    "Data.to_csv('Data/Wikidata/France/France.csv', sep='\\t', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
